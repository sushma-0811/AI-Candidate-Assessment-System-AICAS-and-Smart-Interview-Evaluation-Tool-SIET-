{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30788,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T09:16:53.822004Z","iopub.execute_input":"2024-10-04T09:16:53.822367Z","iopub.status.idle":"2024-10-04T09:16:55.638907Z","shell.execute_reply.started":"2024-10-04T09:16:53.822333Z","shell.execute_reply":"2024-10-04T09:16:55.638175Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:38:46.838100Z","iopub.execute_input":"2024-10-04T19:38:46.838328Z","iopub.status.idle":"2024-10-04T19:38:51.147202Z","shell.execute_reply.started":"2024-10-04T19:38:46.838303Z","shell.execute_reply":"2024-10-04T19:38:51.146301Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.66.5)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.16.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2024.9.11)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")\n#login(token=\"place your token from hugging face\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:39:14.261235Z","iopub.execute_input":"2024-10-04T19:39:14.261763Z","iopub.status.idle":"2024-10-04T19:39:14.709939Z","shell.execute_reply.started":"2024-10-04T19:39:14.261729Z","shell.execute_reply":"2024-10-04T19:39:14.708917Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:39:18.276494Z","iopub.execute_input":"2024-10-04T19:39:18.277495Z","iopub.status.idle":"2024-10-04T19:40:45.703534Z","shell.execute_reply.started":"2024-10-04T19:39:18.277453Z","shell.execute_reply":"2024-10-04T19:40:45.702827Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\nDownloading shards: 100%|██████████| 4/4 [00:50<00:00, 12.75s/it]\nLoading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.16it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:41:01.224745Z","iopub.execute_input":"2024-10-04T19:41:01.225173Z","iopub.status.idle":"2024-10-04T19:41:01.228659Z","shell.execute_reply.started":"2024-10-04T19:41:01.225143Z","shell.execute_reply":"2024-10-04T19:41:01.228014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from difflib import SequenceMatcher\n\ndef generate_question() -> str:\n    \"\"\"\n    Generate a single AI/ML-related question dynamically using a pre-trained model.\n    \n    Returns:\n        A dynamically generated and fully complete question within 100 words not more than that strict rule.\n    \"\"\"\n    # Simplified prompt\n    prompt = \"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule.\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    \n    output_ids = model.generate(**inputs, max_new_tokens=100)  # Max token length to ensure completion\n    question = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    \n    # Post-process to ensure it's a single complete question\n    if \"?\" in question:\n        question = question.split(\"?\")[0] + \"?\"\n    \n    return question\n\ndef get_correct_answer(question: str) -> str:\n    \"\"\"\n    Generate the correct answer for the given AI/ML question using a pre-trained model.\n    \n    Args:\n        question: The AI/ML-related question.\n        \n    Returns:\n        The correct answer for the question.\n    \"\"\"\n    prompt = f\"Provide a correct answer for the question: {question}\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n    \n    output_ids = model.generate(**inputs, max_new_tokens=100)\n    correct_answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    \n    return correct_answer\n\ndef ask_question(question: str) -> str:\n    \"\"\"\n    Ask a single dynamically generated question to the student.\n    \n    Args:\n        question: The question to ask the student.\n        \n    Returns:\n        The student's answer.\n    \"\"\"\n    print(question)\n    student_answer = input(\"Your answer: \")\n    return student_answer\n\ndef calculate_accuracy(student_answer: str, correct_answer: str) -> float:\n    \"\"\"\n    Calculate the accuracy score of the student's response by comparing it with the correct answer.\n    \n    Args:\n        student_answer: The student's answer to the question.\n        correct_answer: The correct answer.\n    \n    Returns:\n        A float value representing the accuracy score between 0 and 100.\n    \"\"\"\n    # Use SequenceMatcher to calculate similarity ratio\n    similarity = SequenceMatcher(None, student_answer.lower(), correct_answer.lower()).ratio()\n    accuracy_score = round(similarity * 100, 2)\n    return accuracy_score\n\ndef analyze_response(student_answer: str, correct_answer: str) -> str:\n    \"\"\"\n    Analyze the student's response by calculating the accuracy.\n    \n    Args:\n        student_answer: The student's answer to the question.\n        correct_answer: The correct answer.\n        \n    Returns:\n        Feedback on the student's response with an accuracy score.\n    \"\"\"\n    accuracy_score = calculate_accuracy(student_answer, correct_answer)\n    \n    # Return only the accuracy score as feedback\n    return f\"Accuracy Score: {accuracy_score}%\"\n\ndef decide_role(average_score: float) -> str:\n    \"\"\"\n    Decide the role based on the candidate's average accuracy score.\n    \n    Args:\n        average_score: The candidate's average accuracy score.\n        \n    Returns:\n        The most suitable role for the candidate.\n    \"\"\"\n    if average_score < 50:\n        return \"Junior AI Engineer\"\n    elif 50 <= average_score < 80:\n        return \"AI Engineer\"\n    elif average_score >= 80:\n        return \"Senior AI Engineer or Data Scientist\"\n\n# New functionality to ask five questions, calculate average accuracy, and decide the role\ndef interview_and_assign_role():\n    \"\"\"\n    Ask five questions, calculate the overall accuracy, and assign a role based on performance.\n    \"\"\"\n    total_score = 0\n    num_questions = 5  # Number of questions to ask\n\n    print(\"\\nStarting the interview...\\n\")\n\n    for i in range(num_questions):\n        question = generate_question()  # Generate a question\n        correct_answer = get_correct_answer(question)  # Get the correct answer\n        \n        student_answer = ask_question(question)  # Ask the question\n        feedback = analyze_response(student_answer, correct_answer)  # Analyze the response\n        \n        accuracy_score = float(feedback.split()[-1].replace(\"%\", \"\"))  # Extract accuracy score from feedback\n        total_score += accuracy_score\n        \n        print(f\"\\n--- Question {i + 1} ---\")\n        print(feedback)\n        print(\"\\n\")\n\n    # Calculate the average score after all five questions\n    average_score = total_score / num_questions\n    print(f\"Overall Accuracy Score: {average_score}%\")\n    \n    # Decide the role based on the overall accuracy score\n    assigned_role = decide_role(average_score)\n    print(f\"The assigned role for this candidate is: {assigned_role}\")\n\n# Example of running the interview process and assigning a role\ninterview_and_assign_role()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T20:58:39.304830Z","iopub.execute_input":"2024-10-04T20:58:39.305233Z","iopub.status.idle":"2024-10-04T21:08:43.518871Z","shell.execute_reply.started":"2024-10-04T20:58:39.305200Z","shell.execute_reply":"2024-10-04T21:08:43.518060Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nStarting the interview...\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule. Here it is:\n\nCan a machine learning model be trained to recognize and respond appropriately to a wide range of human emotions, including subtle and nuanced expressions, without being explicitly programmed to do so?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer:  no it cant do that becuase the prediction cannot be perfect all the time\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Question 1 ---\nAccuracy Score: 0.2%\n\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule. Here is the question:\n\nQuestion 1:\nWhat is the primary purpose of using reinforcement learning in AI, and how does it differ from supervised learning in achieving its objectives?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer:  reinforcement predicts the using agents without classification and regression but supervisied learning needs classification and other point is supervised learning needs target column but reinforcement doesnt need target column\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Question 2 ---\nAccuracy Score: 2.32%\n\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule. Here is your question:\n\nWhat is the primary function of a Generative Adversarial Network (GAN) in deep learning, and how does it differ from a traditional neural network?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer:  The primary function of a **Generative Adversarial Network (GAN)** in deep learning is to generate new data that is similar to a given dataset. A GAN consists of two neural networks: a **generator** and a **discriminator**, which are trained together in a competitive process.   - The **generator** creates fake data (e.g., images, text) from random noise, trying to mimic the real dataset. - The **discriminator** evaluates whether the data it receives is real (from the training set) or fake (from the generator).  During training, the generator improves by trying to \"fool\" the discriminator, while the discriminator gets better at distinguishing real from fake data. This adversarial process leads the generator to produce highly realistic data.  ### Key Differences from a Traditional Neural Network: - A **traditional neural network** typically focuses on tasks like classification or regression, where it learns from input-output mappings to make predictions. - In contrast, a **GAN** focuses on data generation rather than prediction or classification. It leverages the interaction between two models (generator and discriminator) to create new, realistic data samples, which a traditional neural network doesn't do.  GANs are widely used in applications like image generation, style transfer, and data augmentation.\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Question 3 ---\nAccuracy Score: 5.78%\n\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule. Here it is:\n\nWhat is the main difference between a neural network and a deep learning model in the context of AI, and how does this difference impact the approach to training and testing these models?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer:  The main difference between a **neural network** and a **deep learning model** lies in their architecture and complexity:  ### Neural Network vs. Deep Learning Model  1. **Neural Network:**    - A neural network typically refers to a simple network with one or more hidden layers.     - It can consist of a few layers (input, hidden, output) and is often used for basic tasks like linear regression or binary classification.    - Common types include feedforward networks and basic convolutional neural networks (CNNs).  2. **Deep Learning Model:**    - A deep learning model is a specific type of neural network that contains multiple hidden layers (often more than three).     - This increased depth allows the model to learn complex representations and patterns from the data.    - Deep learning models can include various architectures, such as CNNs, recurrent neural networks (RNNs), and transformers, designed for specific types of data (e.g., images, sequences).  ### Impact on Training and Testing  1. **Training:**    - **Neural Networks:** Simpler architectures typically require less data and computational power. They may converge faster but can struggle with complex datasets due to their limited capacity.    - **Deep Learning Models:** These require larger datasets to prevent overfitting and ensure effective learning of the deeper layers. Training deep models often involves advanced techniques such as dropout, batch normalization, and regularization. They also typically demand more computational resources and time due to the increased number of parameters and the complexity of the optimization landscape.  2. **Testing:**    - **Neural Networks:** Testing simpler models can often be quicker and easier due to fewer parameters. Evaluation metrics may be straightforward, focusing on accuracy or loss.    - **Deep Learning Models:** Testing deep models involves not only evaluating accuracy but also analyzing metrics related to overfitting, generalization, and performance across different data distributions. They may require careful tuning of hyperparameters and validation techniques like cross-validation to assess their robustness.  ### Summary In summary, the main difference between a neural network and a deep learning model is their architectural complexity. This difference significantly influences the approach to training (with deep models requiring more data and advanced techniques) and testing (with deep models needing more thorough evaluation and analysis).\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Question 4 ---\nAccuracy Score: 4.93%\n\n\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate a fully completed and single question about AI or machine learning within 100 words and not more than that strict rule. Here is the question:\nQuestion: What is the primary difference between a feedforward neural network and a recurrent neural network (RNN) in the context of deep learning?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer:  The primary difference between a **feedforward neural network** and a **recurrent neural network (RNN)** in the context of deep learning lies in their architecture and the way they process data:  ### 1. Data Flow  - **Feedforward Neural Network:**   - Data flows in one direction—from the input layer through hidden layers to the output layer.   - There are no cycles or loops in the architecture, meaning that the output from one layer does not influence the input to the same layer or previous layers.   - It is primarily used for static data, such as image classification or regression tasks.  - **Recurrent Neural Network (RNN):**   - Data can flow in both directions, allowing the network to maintain a memory of previous inputs.   - RNNs have loops that enable them to use the output of the previous time step as part of the input for the current time step.   - This architecture is particularly effective for sequential or time-series data, such as natural language processing, speech recognition, and other tasks where the order of inputs matters.  ### 2. Memory and Context  - **Feedforward Neural Network:**   - Lacks memory of past inputs; each input is processed independently.   - Suitable for tasks where the relationship between inputs does not depend on previous inputs.  - **Recurrent Neural Network (RNN):**   - Maintains a hidden state that serves as memory, capturing information about previous inputs in the sequence.   - This ability to retain context makes RNNs suitable for tasks where past information is essential for understanding the current input (e.g., predicting the next word in a sentence).  ### 3. Applications  - **Feedforward Neural Network:**   - Commonly used for tasks like image classification, structured data regression, and general pattern recognition.    - **Recurrent Neural Network (RNN):**   - Specifically designed for sequential data applications, such as language modeling, machine translation, and time-series forecasting.  ### Summary In summary, the key difference between feedforward neural networks and RNNs is how they process data. Feedforward networks process inputs independently and lack memory, while RNNs can retain information from previous inputs through their recurrent connections, making them suitable for sequential data tasks.\n"},{"name":"stdout","text":"\n--- Question 5 ---\nAccuracy Score: 4.68%\n\n\nOverall Accuracy Score: 3.582%\nThe assigned role for this candidate is: Junior AI Engineer\n","output_type":"stream"}]}]}
